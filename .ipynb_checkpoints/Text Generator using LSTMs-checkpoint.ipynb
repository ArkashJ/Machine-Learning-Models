{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35e9a4fd-4d78-41cf-9f2b-2cb31d0983b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f96096e-2117-4101-8315-c126e333cf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/arkashjain/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a23901c-d115-4809-8123-56a35debbfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 66 files..\n",
      "corpus length: 1915949\n"
     ]
    }
   ],
   "source": [
    "corpora_dir = \"/Users/arkashjain/nltk_data/corpora/state_union\"\n",
    "corpora_dir\n",
    "\n",
    "file_list = []\n",
    "for root, _ , files in os.walk(corpora_dir):\n",
    "    for filename in files:\n",
    "        file_list.append(os.path.join(root, filename))\n",
    "\n",
    "print(\"Read\", len(file_list), \"files..\")\n",
    "\n",
    "docs = []\n",
    "\n",
    "for files in file_list:\n",
    "    with open(files, 'r') as fin:\n",
    "        try:\n",
    "            str_form = fin.read().lower().replace('\\n','')\n",
    "            docs.append(str_form)\n",
    "        except UnicodeDecodeError:\n",
    "            pass\n",
    "text = ' '.join(docs)\n",
    "\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a0cdea5-90e1-438f-a3d6-da249f7ab153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique characters: 57\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('Total number of unique characters:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars)) #characters to indices\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars)) #indices to characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df897fcd-77d4-4192-ae26-eda5ecc8c249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences 638637\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "#cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('nb sequences', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype = bool)\n",
    "y = np.zeros((len(sentences),len(chars)), dtype = bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "    \n",
    "def sample(preds, temperature = 1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    \n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    print()\n",
    "    print('------ Generating text after Epoch: %d' %epoch)\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- Diversity', diversity)\n",
    "        \n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: ' + sentence + '\"\"')\n",
    "        sys.stdout.write(generated)\n",
    "        \n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1\n",
    "            \n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            \n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            \n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "            \n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "        \n",
    "    model.save_weights('saved_weights.hdf5', overwrite=True)\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end = on_epoch_end)\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b7cace0-59d2-4439-b115-1de841e5c2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Epoch 1/5\n",
      "4989/4990 [============================>.] - ETA: 0s - loss: 2.0940\n",
      "------ Generating text after Epoch: 0\n",
      "----- Diversity 0.2\n",
      "----- Generating with seed: rican americans. i ask congress to refor\"\"\n",
      "rican americans. i ask congress to refore of the resenter and the reges of the resenged to and the reseng to and the readers and and and the reveres and the readers of and the reader and the readers of and the congress of the resendent to and the reader and the resenged and in the congress of and the reader and the reader of and the resend the reader and the rest and the readers and the reader and and the congress of the resporsest and \n",
      "----- Diversity 0.5\n",
      "----- Generating with seed: rican americans. i ask congress to refor\"\"\n",
      "rican americans. i ask congress to refore in the regited in the rase the defing thas year the hargh the mane of and in and american to the cars. and the reale and ervery to lake grents, and the sighes not the governing the world for of remurity and but the readent progection for axeray heard to lanked congress in the readers and the has a dease for the reader and the rest refuned con the reares endressions of and the congression but we \n",
      "----- Diversity 1.0\n",
      "----- Generating with seed: rican americans. i ask congress to refor\"\"\n",
      "rican americans. i ask congress to refora of of memerato.. 'urp, a thunge it that of and archeames can the invere hpansidm of wherely febued to p1k.. the kenthrice. shar seaus of man corerty, to leve venent- op of erispiale's.tare toytrecoon, in, our all delament uscona, intal and in we canug then to the werrs i poose of canmind wiras anganess for a, ous comperic almssice, the is amfitionssew, mmendtity acoingrisgrace and huch peose pea\n",
      "----- Diversity 1.2\n",
      "----- Generating with seed: rican americans. i ask congress to refor\"\"\n",
      "rican americans. i ask congress to refore thhice goobturine stats we poontvenc. ifto ad renegs dranghlefy, who  is to preburitioncan on keape.and rebplenipdald re.viges, arka, hope ago hovery, ad have trako., frinys. of this every, thay ofnerce zage lowld arl kinginust fursome, -fond, te, goopmont andrecato.ingy be, crnedgaborpey.ceafmendmont bications rede bregechey in wistrod coustury os alliof ald- itlataiy lives the mang-whrourently\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4990/4990 [==============================] - 488s 97ms/step - loss: 2.0940\n",
      "Epoch 2/5\n",
      "4990/4990 [==============================] - ETA: 0s - loss: 1.6357\n",
      "------ Generating text after Epoch: 1\n",
      "----- Diversity 0.2\n",
      "----- Generating with seed: hing america reads, sending literally th\"\"\n",
      "hing america reads, sending literally that we can for the congress of the comming the realons that and the congress of the comming the prosests to the congress and the comminists of the congress and the congress of the congress of our community of the congress of the congress and the comming the security and the congress of the congress of our comming the comming the comminsion of the comming the comminists and the congress and the comm\n",
      "----- Diversity 0.5\n",
      "----- Generating with seed: hing america reads, sending literally th\"\"\n",
      "hing america reads, sending literally that and many defensent as new country of have and comitions of the congress is the world and commistives and can fell american and the programs of the for the americans new to the compension with a continue sound but in the congress we can te production in the congress and whone of a procram courtration of the commistion of the programs in the fiscal are resporsing to the world continues to the con\n",
      "----- Diversity 1.0\n",
      "----- Generating with seed: hing america reads, sending literally th\"\"\n",
      "hing america reads, sending literally the podate easter of owe wime mosh baiging some was affect stritle-nearsy on the continies.inoliful has all andaling leaders of ecentiny to elure that shibling out laysing mosts and taxace wolkn oulled not mitthonive willops antion, our addinipstons of befice e interted to dos ffor out as antejure. we seve of yauch sirethis to provide is atstate of batition lepares produces that his iscalsh proweds \n",
      "----- Diversity 1.2\n",
      "----- Generating with seed: hing america reads, sending literally th\"\"\n",
      "hing america reads, sending literally thosist sabiticy if the amerisaningm i sedes in ruwandy nation cannities in the fatial solfors adsuldsnce anvilueds of opromicity sore of muginowiof droud, e tony furm inchoudatecaly on luggem. we natriur.  plas dodah, that telp.ap notion to kely to dracht ay injose of havings for oul penacopy ac5 fiming eefongs, ad thes cemare sa aily hirh petinute, ourshope agurnansal to goway, has fey ligdicy pla\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4990/4990 [==============================] - 506s 101ms/step - loss: 1.6357\n",
      "Epoch 3/5\n",
      "4989/4990 [============================>.] - ETA: 0s - loss: 1.4737\n",
      "------ Generating text after Epoch: 2\n",
      "----- Diversity 0.2\n",
      "----- Generating with seed: for revision of the immigration laws wil\"\"\n",
      "for revision of the immigration laws will be recond of the program to the production in the congress of the fight to the families in the destrice the security of the prices of the united states of the that the world of the states of the state of the families and the state of the fight to the same of the the that the peace of the world and the state of the state of the congress and the states of the that we make the state of the american\n",
      "----- Diversity 0.5\n",
      "----- Generating with seed: for revision of the immigration laws wil\"\"\n",
      "for revision of the immigration laws will be a great can federal production in this people be middly will end the past you have do not to achieve the world and our strength of the development that the indevertanies in this cannot the consention and basines to the ension and propose them to invertand mank on the defense of the increase of the more sems see in the senvice, or program and the american people is a part before and last years\n",
      "----- Diversity 1.0\n",
      "----- Generating with seed: for revision of the immigration laws wil\"\"\n",
      "for revision of the immigration laws will inclitions and become oth(applicy clace to membair the reth yinally becausing, welk commuting call or any pregident. by be more sere you as the -ot stanged wall-propose an amold. this the stand of these leads in rese of enecolian for our effort. and it house lost in increase which and the reviurts of ockica leadul nor religination of the belise, a ofmerd and to argonimitary soll, that the world.\n",
      "----- Diversity 1.2\n",
      "----- Generating with seed: for revision of the immigration laws wil\"\"\n",
      "for revision of the immigration laws will nation.i well.. stimilly apriess murding.in toconce chance all those wow--we than no thingb8ural dene. v thank vawich- our the bigitged by recendures.are rejaid in ancess of of throinge of that thre0 belys may the the tho seep they'reswing knact office . rassureging helf that we shopth both tory efferen orcentays and ryarce. no notcem, ourading our omenwition, and i mugnoridf wereds; we orver. i\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4990/4990 [==============================] - 485s 97ms/step - loss: 1.4737\n",
      "Epoch 4/5\n",
      "4990/4990 [==============================] - ETA: 0s - loss: 1.3876\n",
      "------ Generating text after Epoch: 3\n",
      "----- Diversity 0.2\n",
      "----- Generating with seed:  being matched by the emergence of new t\"\"\n",
      " being matched by the emergence of new the success and the fair and success of the congress to the congress to the first and the country and a great reserve the congress to have a community in the community and the congress of the congress and the congress and the congress and the country and the congress to the congress to the congress of the congress to the first and the congress to the congress to the congress to a sure the congress \n",
      "----- Diversity 0.5\n",
      "----- Generating with seed:  being matched by the emergence of new t\"\"\n",
      " being matched by the emergence of new the many for the security, dove measures and the price in the many of our resources of a way and economy of the befene and working have seen to great the than a right action of the congress to the congress to increased a discans of the realin of the states and our successis and land, i am in the friences are a country of the fiscal into the congress to the union in all of the support and develop an\n",
      "----- Diversity 1.0\n",
      "----- Generating with seed:  being matched by the emergence of new t\"\"\n",
      " being matched by the emergence of new this year. to musare controut democraticy, the baggerswapip is all weyst're greatures of duriches. we're our nuil on a made good, sciplan0ly america. for toggatoly will woult do new alon, it is these has steprer about the commonn, i must and toda, and reathing a session of incompaidencsuprouls continually proserts.we seek to go other healthed by foreally falt of itwirs never high hource to subsion \n",
      "----- Diversity 1.2\n",
      "----- Generating with seed:  being matched by the emergence of new t\"\"\n",
      " being matched by the emergence of new the initiational is trainity develoument to tealprovy dene will protol. i naty mil have rud by to yof being ty heoping, every celnciliagation. dur'nds oucled, are fourty hatiral inflation jos- i having come hose reparrots and staping facing on the succhmacian, we must ot nurgor for meacteref givatpors our balable agienal cormunitgefoved zight to fut. youngy, alew andnrwe-mann our hoarthed policies.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4990/4990 [==============================] - 499s 100ms/step - loss: 1.3876\n",
      "Epoch 5/5\n",
      "4989/4990 [============================>.] - ETA: 0s - loss: 1.3360\n",
      "------ Generating text after Epoch: 4\n",
      "----- Diversity 0.2\n",
      "----- Generating with seed: very human activity is pressed into serv\"\"\n",
      "very human activity is pressed into serve our country and the programs to the state of the congress and the state of the united states and the same of the first of the committen resources and the state of the state of the world and to the congress the state of the world. the prosperity of the many of the military for a serious of our country and the american people and the congress and the common state of the congress to the american pe\n",
      "----- Diversity 0.5\n",
      "----- Generating with seed: very human activity is pressed into serv\"\"\n",
      "very human activity is pressed into service the congress in the budget for an established to the congress on the senaration of attack of the basic proposes and the any of children and the world and congress on its communities and come to help the same on the folution of the congress, and the first war deficit the high product the programs in the many of the substaning the fact both the social security. the tax free world to the internat\n",
      "----- Diversity 1.0\n",
      "----- Generating with seed: very human activity is pressed into serv\"\"\n",
      "very human activity is pressed into serve better ard people are somethip has closed this farlend task now feer grainet of our will he ling rome any onge fasce doy's home resists age.no magement of a prigations. it will be the federal day and male. laces the obla --we are what clear undelstmonted and terrorists, and sa certain the which will be century , by insucturated sently economic contectic limes, that we we hape, i should. the righ\n",
      "----- Diversity 1.2\n",
      "----- Generating with seed: very human activity is pressed into serv\"\"\n",
      "very human activity is pressed into serve on mrihupe stopt many evirernay will befole valunesship toving cut this fights, least victory quds. as citibers inqumatle; bo povinithe and out, but qued yetery country lastouh, or veetwrentw, non impasir hidfier creatista cuses and residve a peafomon free efficiens. in a new mucomand out ally to youth, our citual enduble and if many athans whonxer0 federal seconding this yefices, tocorn and imm\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4990/4990 [==============================] - 464s 93ms/step - loss: 1.3360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae998c70d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Building model...')\n",
    "#size of the vector in the hidden layer\n",
    "hidden_size = 128\n",
    "# Initializing model sequence\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_size, input_shape=(maxlen, len(chars))))\n",
    "\n",
    "#Adding the output layer that is softmax of the number of characters\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "#optimization through RMSprop\n",
    "optimizer_new = RMSprop()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_new)\n",
    "\n",
    "model.fit(x, y, \n",
    "          batch_size = 128, \n",
    "          epochs = 5, \n",
    "          callbacks = [print_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a73166a-287d-4354-ac12-5ae3c10b77f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4989/4990 [============================>.] - ETA: 0s - loss: 1.2999\n",
      "------ Generating text after Epoch: 0\n",
      "----- Diversity 0.2\n",
      "----- Generating with seed: this time conducting a study of the enti\"\"\n",
      "this time conducting a study of the entire partnership and the defense of the congress and the congress to the state of the present the congress to state of the congress of the congress in the congress and the congress to a sense of the congress to the congress of the congress of the world and the congress to state our congress to serve our national security of the world of the president and the congress of the congress of the congress \n",
      "----- Diversity 0.5\n",
      "----- Generating with seed: this time conducting a study of the enti\"\"\n",
      "this time conducting a study of the entire policy of the congress will be research and security is the ligit of training police. and we must propose the sense of the congress and to produce the congress and sureloge and the defense of the congress betand the congress to state of in the congress and the cold with the promote partnership of the states of the congress will be continued in the congress and the american regime is to respons \n",
      "----- Diversity 1.0\n",
      "----- Generating with seed: this time conducting a study of the enti\"\"\n",
      "this time conducting a study of the entinowy right of peace. as we meen election, well, we make jumanth the ming us trade cares to begin to their good federal lives.i will meet contrmen'ment boon. we can't be no many mankatained postinge, use, they grans. the free communities, and prond their gold for gish on i challenge even whether the taxes of the poseble and defensing peace in a scanning now beaubly seep expansingment5. district cov\n",
      "----- Diversity 1.2\n",
      "----- Generating with seed: this time conducting a study of the enti\"\"\n",
      "this time conducting a study of the ention hert will be diswiels.\". my growth.was will be dritaintable should. looked of  parellyigna. any peace a men to eaching to uss solize thrie disenity competitoks. a dieses a black ood, new friends, much saved.a our. wewer we shall is, leter paysowni2fy of pay goide ontzainged ever sand--faway., my studdry. and goods, restures of interng nations almost thing a sunsource will fonning providedlement\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4990/4990 [==============================] - 478s 96ms/step - loss: 1.3000\n",
      "Epoch 2/5\n",
      "4989/4990 [============================>.] - ETA: 0s - loss: 1.2731\n",
      "------ Generating text after Epoch: 1\n",
      "----- Diversity 0.2\n",
      "----- Generating with seed: nd domination has appeared again, and se\"\"\n",
      "nd domination has appeared again, and see that i have already dependent and the need to the congress to a stand of the strength of the security in the families and strength and only and the strength of americans and the world that we can also be in a stand of international programs and the responsibility in our complete conservation and the resources and the security in the congress to prove the restriction of the united states and the \n",
      "----- Diversity 0.5\n",
      "----- Generating with seed: nd domination has appeared again, and se\"\"\n",
      "nd domination has appeared again, and security of our new responsibility with the congress the world war in proved in the national parents of the congress to have been security and the missiles and all of the growth and americans, our trade for this new enduring the citizens of the last strengthen the congress a stands and the national new war crime to preserve the state of the national determination of the world is a families of democr\n",
      "----- Diversity 1.0\n",
      "----- Generating with seed: nd domination has appeared again, and se\"\"\n",
      "nd domination has appeared again, and sevenulastic will fulling of abod and itsivilation 194gearis, over mied for woll-renaters freed, wespifal of restractistically its spiriting the we critingn and and who woading, orvinaling communist nations for freedoms are through held. and i am ask the home. first persons in aspained of sestonueaned home of the fimment. we can.  soviet templomies of about the navies in seedist, on their who are a \n",
      "----- Diversity 1.2\n",
      "----- Generating with seed: nd domination has appeared again, and se\"\"\n",
      "nd domination has appeared again, and seek tood beginning, 'o level abiniating afternting for the sextor, pubsish1s free women and challenge beatt spaning dobboll that expenditure of throngy it detainivally, taki, heloestly out of if i ammilit towirnwew aporal endersions to a surelis realing encourage. pabsefuc, wich unceptare and fimstan koons far xand of feitian in put them and that i propose.that. efec1sity, contrumentys fination. ve\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4990/4990 [==============================] - 455s 91ms/step - loss: 1.2731\n",
      "Epoch 3/5\n",
      "4989/4990 [============================>.] - ETA: 0s - loss: 1.2527\n",
      "------ Generating text after Epoch: 2\n",
      "----- Diversity 0.2\n",
      "----- Generating with seed: rol the growth of the so-called uncontro\"\"\n",
      "rol the growth of the so-called uncontrol of the congress to serve a stronger and other congress to the end of the first and a sure that the congress of the congress and the congress to fail the tax can as a single and a progress and the congress to the congress to the congress to the national defense of the congress to real who have been survivisural and the people of the congress to earle of the first and productivity and the congress\n",
      "----- Diversity 0.5\n",
      "----- Generating with seed: rol the growth of the so-called uncontro\"\"\n",
      "rol the growth of the so-called uncontrol of the united states and the now to the congress of our foreign policy of the world will can to our middle easter. this is in the world age is the political cause of the recession and prosperous to a return to action to continue to be midering of the congress will can at the past of the people of our families and the congress of the peace of many him the final service of our freedom of our inter\n",
      "----- Diversity 1.0\n",
      "----- Generating with seed: rol the growth of the so-called uncontro\"\"\n",
      "rol the growth of the so-called uncontrolly consuding our time. i child equalially conpeet deal well. we have all our freedom and heagenes. our geisenty pay optrans, and that within to we half employment will emer$mare had to have they propreat to meet the civil rates in america's would all afgimibally be would somet momenttore conservation to realy auther to provide theild to endinged keet higher communist work. but i wan this chapacte\n",
      "----- Diversity 1.2\n",
      "----- Generating with seed: rol the growth of the so-called uncontro\"\"\n",
      "rol the growth of the so-called uncontrowian payrile ngeelly, not dearement people of was you can at mie- in union of the vilating social heal earnaine fellobocnation of haven, howest crusis, afounts car go the overcht drivined fivey increase otteater.gumits rather and such kloadly, as this, energy oper impassy as ravos matter hasfor for un i surdent eugenes united policies,coking the thinging vallan freedom to begon health neight 50 ye\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4990/4990 [==============================] - 453s 91ms/step - loss: 1.2527\n",
      "Epoch 4/5\n",
      "4989/4990 [============================>.] - ETA: 0s - loss: 1.2358\n",
      "------ Generating text after Epoch: 3\n",
      "----- Diversity 0.2\n",
      "----- Generating with seed: n the world.let's work together to meet \"\"\n",
      "n the world.let's work together to meet the security of the congress to the program and success are standards of the world are a recovery in the last year and a single congress and the congress and to serve a strong and the congress of the defense and energy that is the congress and the congress and the congress of the congress to the congress to the congress to the congress to serve our construction of the world of the faith of the def\n",
      "----- Diversity 0.5\n",
      "----- Generating with seed: n the world.let's work together to meet \"\"\n",
      "n the world.let's work together to meet the strong and interest conservation and every american programs in the fores of the congress in the people of the congress to make the program to the entire economic state of the congress in the american people that the congress is the congress to his not jobs has been accomplished for the war we will continue to the trust of the entire ending constructive are representative can assist the free m\n",
      "----- Diversity 1.0\n",
      "----- Generating with seed: n the world.let's work together to meet \"\"\n",
      "n the world.let's work together to meet this challenges and make gut the constitutional special intend to the history areas conception an every teach. manygaining special straticyhip of fighting fore that our iblougary in the provide, or  improve conscorded and success in our commitments. much seruate groators of the friends of sments and to work for over readorian, disnustation.the cleac. it. all was to herg schools against batin are d\n",
      "----- Diversity 1.2\n",
      "----- Generating with seed: n the world.let's work together to meet \"\"\n",
      "n the world.let's work together to meet the dissubitionjs'onewhe excr.estabjs for the previouing us can he mategisure,  and durwex people, torown ifbocrificerand yeejescy.thinks to have you jove, forthe about could xeher nowable.busipes, put bit to ourps, and as bef1re enduce problemers intildities for thousjocates mobely now did is require our.thing fiscally including streablly alroided indevendent, andk coding last dicappriants remage\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4990/4990 [==============================] - 450s 90ms/step - loss: 1.2358\n",
      "Epoch 5/5\n",
      "4989/4990 [============================>.] - ETA: 0s - loss: 1.2216\n",
      "------ Generating text after Epoch: 4\n",
      "----- Diversity 0.2\n",
      "----- Generating with seed: of support for medical schools require s\"\"\n",
      "of support for medical schools require surely to the proposals and the states of the farmers and the defense of the first and the congress to the congress the recommendations of the congress of the people of the people of the congress and the congress the states of the union assistance to respect the states of the federal american people of the congress the federal growth of the states of the people of the first and the promotes the sta\n",
      "----- Diversity 0.5\n",
      "----- Generating with seed: of support for medical schools require s\"\"\n",
      "of support for medical schools require social security of the most of the world will never one started in an expanded rights, will continue to the expectation and should never providing them of the resources of the first the states may come the resisting general life. it's being the needs for a successis resear that greater new their will be destinged the government security in the world accountance of the past and respand the same our \n",
      "----- Diversity 1.0\n",
      "----- Generating with seed: of support for medical schools require s\"\"\n",
      "of support for medical schools require shorter tax care and longhhatedkers case fellobors. the union.thes needed in the marrales of gains. it providing a mar, can will essential responsibility. i hope of the fiscal year. we and our nationica strategul the people of mankind fall on their allies of the helon' nuclear steend--we have all atmert of a tax in the gledical people who lose increasent statemons repartist, indevite our union drug\n",
      "----- Diversity 1.2\n",
      "----- Generating with seed: of support for medical schools require s\"\"\n",
      "of support for medical schools require social saunders, my a poliopcands that africaytoniansune programs react and definesiors . all save their resturence direction deficieling is nues-needed by all cause. the surulue. - if confidences in in-own,. let's health.n.thes are emplove need fow thereasing , people of man.this greary atmest is remo-liubleming a cealer will be dectaik american axpace spocen with lock. hevefer devater. bysind tax\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4990/4990 [==============================] - 451s 90ms/step - loss: 1.2216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faeaeb56640>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for continued training\n",
    "model.load_weights(\"saved_weights.hdf5\")\n",
    "\n",
    "model.fit(x, y, \n",
    "          batch_size = 128, \n",
    "          epochs = 5, \n",
    "          callbacks = [print_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751aaf48-4d86-43c8-9158-e575234077a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
